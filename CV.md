# Alexnet

多个CNN层堆叠而成的经典卷积神经网络，用于图像分类的任务

- 使用了ReLU激活函数，防止深层次的网络导致**梯度消失**
- 使用Dropout正则化，解决**过拟合问题**
- 使用池化层进行进行**降维**

# GoogleNet

传统CNN通多堆叠卷积层可以学习到图像更多特征，但会导致

- 计算量爆炸
- 梯度消失
- 过拟合

Googlenet设计了宽而深的结构，**创造性**引入了**Inception模块**和**辅助分类器模块**



**Inception模块**

![image-20250804105749792](C:\Users\23967\AppData\Roaming\Typora\typora-user-images\image-20250804105749792.png)

- 并行多尺度卷积：在同一层并行使用$1 \times 1 、 3 \times 3、5 \times 5 $和$3 \times 3$最大池化，融合不同感受野的特征
- 先使用$1 \times 1 $卷积进行降维，压缩通道数，同时加上ReLU，可以**显著降低参数量**

![image-20250804105823459](C:\Users\23967\AppData\Roaming\Typora\typora-user-images\image-20250804105823459.png)

**辅助分类器模块**

![image-20250804110823817](C:\Users\23967\AppData\Roaming\Typora\typora-user-images\image-20250804110823817.png)

- GoogleNet有**3个输出层**，其中**2个是辅助分类层**
- 训练模型时，将2个辅助分类器的损失乘以权重加到总损失上
  - 辅助分类器也能预测类别，在整个网络中起到一个调整的作用，可以防止网络发生**过拟合**
  - 也可以加速梯度传递，防止梯度消失

# Resnet

2015年由何凯明团队提出，利用**短路连接**解决深度卷积神经网络中**梯度消失**的问题
$$
H(x) = x  + F(x)
$$
这样使得网络在**最差情况下也能获得和输入一样的输出**，不会出现**网络退化**的问题

![image-20250804145938060](C:\Users\23967\AppData\Roaming\Typora\typora-user-images\image-20250804145938060.png)

**ResNet Block**

`BasicBlock`不会对每一个block的输出进行升维

`BottleNeck`会对每个layer的第一个block的输出进行升维，其输出通道数是输入中间通道数的4倍

二者结构如下所示![image-20250804154119715](C:\Users\23967\AppData\Roaming\Typora\typora-user-images\image-20250804154119715.png)

- **BasicBlock**
  - **从Layer2开始，每个 layer 的第一个 Block 都会升维**，而后续 Block 只是保持这个维度不变
  - 两个$3\times 3$的卷积核，输出通道为64
  
  - **block**的输入输出通道数相同
  
  - 重点
    1. 在**第1个layer**中通道数**不增加**
    2. 进入到第2个layer的第1个block，**通道数增加**，但在后面的block（相同layer）中**通道数不变**
  


- **BottleNeck**
  - **每个Layer的第一个 Block 都会升维**，而后续 Block 只是保持这个维度不变
  
  - 将$3\times 3$的卷积层替换为$1 \times 1 + 3 \times 3 + 1 \times 1$
  
  - 先通过$1 \times 1$的卷积核进行通道降维，巧妙**扩张或缩减特征图的维度**，一般降到输入维度的四分之一
  
  - 再用$3 \times 3$进行主卷积
  
  - 最后用$1 \times 1$进行通道升维，一般升到**输入中间通道数**的4倍
  
  - 重点
    1. 经过每个layer的第1个block之后通道数都会上升，但在后面的block（相同layer）中通道数不变
    2. 通道数增加至**输入中间通道数**，也就是经过$1\times 1$的卷积的输出通道数的**4倍**
    3. 输入中间通道数会比输入通道数小**二分之一**
  

可以减小计算量，同时保证**输入输出维度一致，可进行残差连接**



**各类别ResNet一览**

![image-20250805173724557](C:\Users\23967\AppData\Roaming\Typora\typora-user-images\image-20250805173724557.png)

# VGG

深度卷积神经网络，固定卷积核大小为$3 \times 3$，一个非常经典的架构

**使用多个小卷积核（$3 \times 3$）代替大卷积核（如 $5 \times 5$, $7 \times 7$）**

- 每层使用固定大小的 **$3 \times 3$ 卷积核**
- 步幅为 1（stride = 1），**padding=1**，保证特征图大小不变
- 通过**堆叠多个 $3\times3$ 卷积**，获得更大的感受野

![image-20250805182841345](C:\Users\23967\AppData\Roaming\Typora\typora-user-images\image-20250805182841345.png)

# MobileNet

小型网络，可部署在边缘设备上

## 深度可分离卷积

由**深度卷积和逐点卷积**组成（能极大减少计算量），最后进行**归一化和非线性激活**

- **深度卷积**用于**滤波**

  - 对每个**输入通道单独进行空间滤波**，提取局部特征

  - 与普通卷积不一样，每个输入通道**独立使用一个卷积核**，不与其他通道**交互**

- **逐点卷积**用于**合并**
  - 混合通道信息，生成新的特征图

**宽度乘子**

通过系数$\alpha$等**比例减少所有层的通道数**，进一步压缩模型

**分辨率乘子**

通过系数$\rho$**降低输入图像分辨率**，减少计算量

**激活函数**

使用了`ReLU6`，防止**激活值过大**导致量化时**精度损失**
$$
ReLU6(x) = min(ReLU(x),6)
$$


## 倒残差结构





**线性瓶颈**

**低维空间**使用ReLU会**丢失部分特征信息**（如负值被置零），因此在最后一层移除ReLU，改用**线性激活**



# Vit

贡献：**首次将Transformer应用于图像分类**，证明自注意力机制可**完全替代传统卷积操作**

**工作流程**：

1. 将图像进行分块，**分成多个patches**，将图像展平为序列
2. 送入**线性投影层**，将patches投影成D（通常是**768**）维向量，并且加**入位置编码（绝对位置编码）**，再加上一个`[CLS]`Token（类似Bert）
3. 送入transformer的encoder层，**[CLS] Token会与所有patch交互**，但其他patch之间**也互相计算注意力**
4. 从encoder层出来后，将`[CLS]`Token**送入**全连接层进行分类

**局限性**

1. 依赖**大规模数据集**，在小规模数据集上泛化能力不佳
2. **不像传统CNN具有针对图像的归纳偏置（Instructive Bias）**，也就是模型没有潜意识要去怎么处理图像，在小的数据集上鲁棒性差
3. **对算力要求高，难以处理大分辨率图像**， 因为要把图像分割成很多个patch，还要进行全局注意力计算，对算力要求高

![image-20250804103117355](C:\Users\23967\AppData\Roaming\Typora\typora-user-images\image-20250804103117355.png)





## Deit

旨在解决**Vit在小数据集上泛化能力不佳的**问题，引入了**知识蒸馏**并且**改进了训练策略**

**知识蒸馏**（distillation）

- 使用CNN或者Vit为教师模型进行知识蒸馏，**双教师协同蒸馏**
- Deit相对于Vit在encoder的输出层加入了一个`[distill]`Token，用于接受教师模型的知识
  - `[distill]`专门从教师模型中提取知识，计算教师模型输出的KL散度损失
  - `[CLS]`计算真实标签的交叉熵损失
- 硬标签（hard distillation）：限制两种模型输出的**类别标签**尽可能接近
- 软标签（soft distillation）：限制两种模型输出的**类别分布**尽可能接近，使用**KL散度**进行分布距离的衡量

**训练策略优化**

- 优化器的改进
- 知识增强
- 正则化等





## Swin Transformer





# 图像分割

**语义分割（Semantic Segmentation）**

- 为图像中的**每个像素**分配一个类别标签，**不区分同类对象的不同实例**（会将图中所有的人归为**同一类**）
- **只关注像素类别**

**实例分割（Instance Segmentation）**

- 在语义分割的基础上，**区分同一类别的不同实例**（如区分图中不同的个体）

**全景分割（ Panoptic Segmentation）**

- 统一**语义分割和实例分割**，要求对图像中**所有像素**进行分类，并区分**可数对象（如车辆、人）和不可数区域（如天空、道路）**

![image-20250806105614387](C:\Users\23967\AppData\Roaming\Typora\typora-user-images\image-20250806105614387.png)

# U-Net

- Unet采用了**编码器-解码器架构**，并加入了**跳跃连接**，将**浅层的高分辨率特征**直接传递到解码器中，有助于**弥补上采样过程中的细节丢失**
- 适合应用于小型数据集，常用于医学影像分割
- 常用于语义分割

![image-20250805103319336](C:\Users\23967\AppData\Roaming\Typora\typora-user-images\image-20250805103319336.png)

**工作流程**

- 输入图像为$1 \times 572 \times 572$大小
- 蓝色箭头卷积参数为`in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=0`，每进行一次卷积和ReLU，**图像尺寸`-2`**，通道数**逐层增加至1024**
- 最大池化的卷积核和步长都设置为2，每进行一次池化，**输出尺寸减半，通道数不变**
- 每进行一次上采样（转置卷积），**通道数减半，图像尺寸加倍**，同时在解码器模块中也会有卷积参与
- 在进行跳跃连接时，需要对下采样的图像进行**裁剪**，之后**与上采样图像进行拼接**

## 深监督

**原始Unet并未使用这个方法**，但这个方法在后来对**Unet的改进中被使用**

我个人认为其作用和**GoogleNet的辅助分类器**大差不差，都是加入了**辅助损失函数防止梯度消失**

深监督指的是在网络的**中间层**添加**辅助损失函数**，简单来说就是加网络的中间层加一个输出层，有利于

- 缓解梯度消失：通过多路径反向传播加速训练
- 改善特征学习
- 早期收敛：浅层网络也能输出初步结果
- 防止过拟合

## IoU（交互比）

用于衡量**预测区域与真实区域**重叠程度的指标，核心思想是计算**两者的交集与并集的比值**，如下，用预测框（A）和真实框（B）的交集除二者并集
$$
IoU = \frac{A\cap B}{A\cup B}
$$
常用于**目标检测，图像分割**等场景

但IoU也有如下缺点：

- 当预测框和真实框完全不重合时，梯度为0，无法优化
- 无法精确反映两者重合度大小，相同的IoU可能**有不同的重合度情况**。如下所示，三种情况**IoU都相等**，但他们的重合度情况不一样，左边最好，右边最差。

![image-20250805110113933](C:\Users\23967\AppData\Roaming\Typora\typora-user-images\image-20250805110113933.png)

## GIoU



## Dice Loss

基于**Dice系数**，用于衡量预测分割掩码和真实掩码的重叠程度，主要用于二分类任务
$$
Dice Loss = 1 - \frac{2\cdot|A\cap B|}{|A| + |B|}
$$
其中：

- $A$：预测的分割掩码（通常为概率图，值在0~1之间）。
- $B$：真实的分割掩码（二值图，0或1）。
- $∣A∩B∣$：预测与真实掩码的交集（逐像素相乘后求和）。
- $∣A∣+∣B∣$：预测和真实掩码的像素值之和。

不依赖**绝对像素数量**，只关注**重叠比例**，对像素少的**目标进行分割仍可以有效优化**

## BCE Loss

二分类交叉熵损失函数，衡量预测概率分布与真实分布的差异，在图像分割领域常与**DiceLoss**结合，
$$
BCE = - \sum _{i=1}^N[y_i\log(p_i) + (1 -y_i)log(1-p_i)]
$$
其中：

- $y_i$：真实标签
- $p_i$：预测概率
- $N$：像素总数

其梯度稳定，且对**小目标友好**（因为**其对像素级分类更敏感**）

但是**在类别不平衡时，会被多数类（背景）主导，导致模型忽视少数类（肿瘤）**

# Deeplab



# Clip



# Blip

